{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3153a786-8d12-4e93-a18a-9d108fac8722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:55:20) \n",
      "[Clang 16.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9630fd7-ab08-43a0-a2f5-779b66ba8596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from unetr.utilsUnetr.transforms import CropBedd, RandCropByPosNegLabeld, ResizeOrDoNothingd\n",
    "from functools import partial\n",
    "from monai.inferers import sliding_window_inference\n",
    "from unetr.networks.unetr import UNETR\n",
    "import os\n",
    "from unetr.model_module import SegmentationTask\n",
    "from monai.transforms import LoadImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import cv2\n",
    "import monai.transforms as transforms\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from monai import transforms\n",
    "from monai.transforms import LoadImage\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pydicom import dcmread\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import rt_utils\n",
    "import pydicom\n",
    "from os import listdir\n",
    "import tqdm\n",
    "import json \n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4746dea5-1cb8-4cbe-91ee-4e8b2be86cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def diceSpecSens(maskGT, maskPred):\n",
    "    predZone=np.where(maskPred==1.0, maskPred,10000)\n",
    "    gtZone=np.where(maskGT==1.0, maskGT,10000)\n",
    "    invPredZone=np.where(maskPred!=1.0, maskPred,10000)\n",
    "    \n",
    "    vp=np.where(gtZone==maskPred,1,0)\n",
    "    fn=np.where(maskPred-maskGT==-1,1,0)\n",
    "    fp=np.where(maskPred-maskGT==1,1,0)\n",
    "    vn=np.where(invPredZone==maskGT,1,0)\n",
    "    \n",
    "    print(np.sum(vp), np.sum(maskPred), np.sum(maskGT))\n",
    "    return (2*np.sum(vp))/(np.sum(maskPred)+np.sum(maskGT)), (np.sum(vn)/(np.sum(vn)+np.sum(fp))), (np.sum(vp)/(np.sum(vp)+np.sum(fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9c84b2-304e-4d03-9415-4abb143408fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation():\n",
    "    dtype= torch.float32\n",
    "    voxel_space =(1.5, 1.5, 2.0)\n",
    "    a_min=-200.0\n",
    "    a_max=300\n",
    "    b_min=0.0\n",
    "    b_max=1.0\n",
    "    clip=True\n",
    "    crop_bed_max_number_of_rows_to_remove=0\n",
    "    crop_bed_max_number_of_cols_to_remove=0\n",
    "    crop_bed_min_spatial_size=(300, -1, -1)\n",
    "    enable_fgbg2indices_feature=False\n",
    "    pos=1.0\n",
    "    neg=1.0\n",
    "    num_samples=1\n",
    "    roi_size=(96, 96, 96)\n",
    "    random_flip_prob=0.2\n",
    "    random_90_deg_rotation_prob=0.2\n",
    "    random_intensity_scale_prob=0.1\n",
    "    random_intensity_shift_prob=0.1\n",
    "    val_resize=(-1, -1, 250)\n",
    "\n",
    "    spacing = transforms.Identity()\n",
    "    if all([space > 0.0 for space in voxel_space]):\n",
    "        spacing = transforms.Spacingd(\n",
    "            keys=[\"image\", \"label\"], pixdim=voxel_space, mode=(\"bilinear\", \"nearest\")\n",
    "        ) # to change the dimension of the voxel to have less data to compute\n",
    "\n",
    "        posneg_label_croper_kwargs = {\n",
    "                \"keys\": [\"image\", \"label\"],\n",
    "                \"label_key\": \"label\",\n",
    "                \"spatial_size\": roi_size,\n",
    "                \"pos\": pos,\n",
    "                \"neg\": neg,\n",
    "                \"num_samples\": num_samples,\n",
    "                \"image_key\": \"image\",\n",
    "                \"allow_smaller\": True,\n",
    "        }\n",
    "\n",
    "        fgbg2indices = transforms.Identity()\n",
    "        if enable_fgbg2indices_feature:\n",
    "            fgbg2indices = transforms.FgBgToIndicesd(\n",
    "                    keys=[\"image\", \"label\"], image_key=\"label\", image_threshold=0.0\n",
    "            ) # to crop samples close to the label mask\n",
    "            posneg_label_croper_kwargs[\"fg_indices_key\"] = \"image_fg_indices\"\n",
    "            posneg_label_croper_kwargs[\"bg_indices_key\"] = \"image_bg_indices\"\n",
    "        else:\n",
    "            posneg_label_croper_kwargs[\"image_threshold\"] = 0.0\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Orientationd(keys=[\"image\", \"label\"], axcodes=\"LAS\", allow_missing_keys=True), # to have the same orientation\n",
    "                    spacing,\n",
    "                    transforms.ScaleIntensityRanged(\n",
    "                        keys=[\"image\"], a_min=a_min, a_max=a_max, b_min=b_min, b_max=b_max, clip=clip, allow_missing_keys=True\n",
    "                    ), # scales image from a values to b values\n",
    "                    CropBedd(\n",
    "                        keys=[\"image\", \"label\"], image_key=\"image\",\n",
    "                        max_number_of_rows_to_remove=crop_bed_max_number_of_rows_to_remove,\n",
    "                        max_number_of_cols_to_remove=crop_bed_max_number_of_cols_to_remove,\n",
    "                        min_spatial_size=crop_bed_min_spatial_size,\n",
    "                        axcodes_orientation=\"LAS\",\n",
    "                    ), # crop the bed from the image (useless data)\n",
    "                    transforms.CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", allow_missing_keys=True), # remove useless background image part\n",
    "                    fgbg2indices,\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=0, allow_missing_keys=True), # random flip on the X axis\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=1, allow_missing_keys=True), # random flip on the Y axis\n",
    "                    transforms.RandFlipd(keys=[\"image\", \"label\"], prob=random_flip_prob, spatial_axis=2, allow_missing_keys=True), # random flip on the Z axis\n",
    "                    transforms.RandRotate90d(keys=[\"image\", \"label\"], prob=random_90_deg_rotation_prob, max_k=3, allow_missing_keys=True), # random 90 degree rotation\n",
    "                    transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=random_intensity_scale_prob), # random intensity scale\n",
    "                    transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=random_intensity_shift_prob), # random intensity shifting\n",
    "                    transforms.ToTensord(keys=[\"image\", \"label\"], dtype=dtype), # to have a PyTorch tensor as output\n",
    "                ]\n",
    "            )\n",
    "    return transform\n",
    "\n",
    "def loadModel(pathModelFile):\n",
    "    #map_location = torch.device('cpu') a faire pas ici mais dans unetr/model_module.py ligne 133 ou try faire ailleurs\n",
    "    model= SegmentationTask.load_from_checkpoint(pathModelFile)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def loadDicomImage(slices_folder):\n",
    "    image=torch.tensor([LoadImage(image_only=True)(slices_folder)])\n",
    "    image=((image/np.max(np.array(image)))*255)\n",
    "    return image\n",
    "\n",
    "\n",
    "def applyTransforms(transform, image):\n",
    "    print(\"----------------\")\n",
    "    print(image.ndim)\n",
    "    print(\"----------------\")\n",
    "    print(\"applyT\", image.shape)\n",
    "    image={\"image\":image, \"label\":torch.zeros_like(image),\"patient_id\":'201905984', \"has_meta\":True}\n",
    "    image=transform(image)\n",
    "    print(\"applyT\", image['image'].shape)\n",
    "    return image\n",
    "\n",
    "def applyTransforms2(transform, image):\n",
    "    # Assurez-vous que l'image est un tensor PyTorch\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    image = (image / torch.max(image)) * 255\n",
    "    if image.ndim == 3:\n",
    "        image = image.unsqueeze(0)\n",
    "    print(\"----------------\")\n",
    "    print(image.ndim)\n",
    "    print(\"----------------\")\n",
    "    data = {\"image\": image, \"label\": torch.zeros_like(image), \"patient_id\": '201905984', \"has_meta\": True}\n",
    "    transformed = transform(data)\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def applyUNETR(dicoImage, model):\n",
    "    label =sliding_window_inference(inputs=dicoImage[\"image\"][None], \n",
    "                                            roi_size=(96, 96, 96), \n",
    "                                            sw_batch_size=4,\n",
    "                                            predictor=model,\n",
    "                                            overlap=0.5)\n",
    "\n",
    "    label = torch.argmax(label, dim=1, keepdim=True)\n",
    "    \n",
    "    size=label.shape\n",
    "    print(\"applyUNETR\", size[1], size[2], size[3], size[4])\n",
    "    dicoImage[\"label\"]=label.reshape((size[1], size[2], size[3], size[4]))\n",
    "    return dicoImage\n",
    "\n",
    "def disapplyTransforms(transform, dicoImage):\n",
    "    dicoImage = transform.inverse(dicoImage)\n",
    "    return dicoImage[\"label\"], dicoImage[\"image\"]\n",
    "\n",
    "\n",
    "\n",
    "def getLabelOfIRM_from_path(pathSlicesIRM, pathModelFile):\n",
    "    image = loadDicomImage(pathSlicesIRM)\n",
    "    transform = transformation()\n",
    "    dicoImage = applyTransforms(transform, image)\n",
    "    model = loadModel(pathModelFile)\n",
    "    dicoImage = applyUNETR(dicoImage, model)\n",
    "    label, imageT = disapplyTransforms(transform, dicoImage)\n",
    "    return image/255, label, imageT\n",
    "\n",
    "# Pipeline complet pour charger, transformer, segmenter et désappliquer les transformations\n",
    "def getLabelOfIRM_from_nifti(nifti_image: nib.Nifti1Image, pathModelFile: str):\n",
    "    transform = transformation()\n",
    "    transformed_image = applyTransforms2( transform, nifti_image.get_fdata())\n",
    "\n",
    "    model = loadModel(pathModelFile)\n",
    "    #dico_image = {\"image\": transformed_image, \"label\": torch.zeros_like(transformed_image)}\n",
    "    dico_image = applyUNETR(transformed_image, model)\n",
    "\n",
    "    label, imageT = disapplyTransforms(transform, dico_image)\n",
    "    return nifti_image.get_fdata() / 255, label, imageT\n",
    "\n",
    "def getLabelOfIRM_from_image(image, mask, pathModelFile):\n",
    "    image=torch.tensor([image])\n",
    "    image=((image/np.max(np.array(image)))*255)\n",
    "    transform = transformation()\n",
    "    dicoImage = applyTransforms(transform, image)\n",
    "    model = loadModel(pathModelFile)\n",
    "    dicoImage = applyUNETR(dicoImage, model)\n",
    "    label, imageT = disapplyTransforms(transform, dicoImage)\n",
    "    return image/255, label, imageT\n",
    "\n",
    "#pathSlicesIRM='/home/aurelien/Documents/Segmentation Métastases cérébrales et méningiomes par IA/UNETR/metastase_IA/BaseDonnée220Patients/201905984/RM'\n",
    "#pathModelFile=\"/home/aurelien/Documents/Segmentation Métastases cérébrales et méningiomes par IA/UNETR/metastase_IA/RunAll4/checkpoints/checkpoint-epoch=1599-val_loss=0.225.ckpt\"\n",
    "\n",
    "#image, label, imageT = getLabelOfIRM(pathSlicesIRM, pathModelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d14e08ef-6071-443b-a0ec-b967307ebee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miseEnDossier(patient_id):\n",
    "    path_newDirRM = os.path.join(meta_data_dir, patient_id, \"RM/\")\n",
    "    path_newDirMETA = os.path.join(meta_data_dir, patient_id, \"META/\")\n",
    "    if not os.path.exists(path_newDirRM):\n",
    "        os.mkdir(path_newDirRM)\n",
    "    if not os.path.exists(path_newDirMETA):\n",
    "        os.mkdir(path_newDirMETA)\n",
    "    for mr in glob.glob(os.path.join(meta_data_dir, patient_id, \"MR*\")):\n",
    "        path_dir, name_file= os.path.split(mr)\n",
    "        os.rename(mr, str(path_newDirRM)+str(name_file))\n",
    "    for rs in glob.glob(os.path.join(meta_data_dir, patient_id, \"RS*\")):\n",
    "        path_dir, name_file= os.path.split(rs)\n",
    "        os.rename(rs, str(path_newDirMETA)+str(name_file))\n",
    "        \n",
    "def fusionMask(mask):\n",
    "        if (type(mask)==list):\n",
    "            premMask = mask[0]\n",
    "            for autMask in mask[1:]:\n",
    "                premMask = np.where(autMask > 0, autMask, premMask)\n",
    "            return premMask\n",
    "        else:\n",
    "            return mask\n",
    "    \n",
    "listeName=[]\n",
    "def load_dicom_with_mask(slices_folder, mask_file):\n",
    "    rt_struct = rt_utils.RTStructBuilder.create_from(slices_folder, mask_file)\n",
    "    maskAllAlone=[]\n",
    "    for i in rt_struct.get_roi_names():\n",
    "        if \"GTV\" in i or \"recid\" in i or \"FRONTAL\" in i or \"GTC\" in i or \"Cerebelleux\" in i or \"PARIET\" in i or \"gtv\" in i or \"M1.\" in i or \"M2.\" in i or \"FRONTAL\" in i:\n",
    "            if \"patient\" not in i and \"POST OP\" not in i and \"Préop\" not in i and \"External\" not in i and \"cav\" not in i and \"Cav\" not in i and \"cavite\" not in i and \"cavité\" not in i and \"Cavité\" not in i and \"PTV\" not in i and \"ANCIEN\" not in i and \"Ancien\" not in i and \"ANC\" not in i and \"Anecien\" not in i and \"PTC\" not in i:\n",
    "                maskAllAlone.append(rt_struct.get_roi_mask_by_name(i).astype(np.float32))\n",
    "                listeName.append(i)\n",
    "    mask = fusionMask(maskAllAlone)\n",
    "    img = np.array(LoadImage( image_only=True)(slices_folder))\n",
    "\n",
    "    img = np.rot90(img)\n",
    "    img = np.flip(img, 0)\n",
    "    img = (img/np.max(img))*255\n",
    "    return img, np.array(mask)\n",
    "\n",
    "\n",
    "def load_dicom_series_without_mask(patient_folder):\n",
    "    img = LoadImage( image_only=True)(patient_folder)\n",
    "    mask = np.zeros_like(img)\n",
    "    return np.array(img), mask\n",
    "  \n",
    "def filter_patients_with_meta(patient_id: str) -> bool:\n",
    "    miseEnDossier(patient_id)\n",
    "    # if no folder in patient directory\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"*\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    # if no named folders \"META\" or \"RM\"\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\"))) == 0 or len(glob.glob(os.path.join(meta_data_dir, patient_id, \"RM\"))) == 0:\n",
    "        return False\n",
    "    \n",
    "    # if no dicom image in the META folder\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\", \"*\"))) == 0:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def filter_patients_without_meta(patient_id: str) -> bool:\n",
    "    miseEnDossier(patient_id)\n",
    "    # if no folder in patient directory\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"*\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    # if no named folders \"META\" or \"RM\"\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"RM\"))) == 0:\n",
    "        return False\n",
    "\n",
    "    if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\"))) != 0:\n",
    "        if len(glob.glob(os.path.join(meta_data_dir, patient_id, \"META\", \"*\"))) != 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4441d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pydicom\n",
    "from io import BytesIO\n",
    "import os \n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from monai.transforms import Compose, Orientationd, ScaleIntensityRanged, CropForegroundd, ToTensord\n",
    "from monai.transforms import RandFlipd, RandRotate90d, RandScaleIntensityd, RandShiftIntensityd\n",
    "import torch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from unetr.model_module import SegmentationTask\n",
    "\n",
    "# fonction de chargement de dicoms en mémoire pour le test de conversion en nifti\n",
    "def load_dicom_files_from_directory(directory_path):\n",
    "    dicom_datasets = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'rb') as file:\n",
    "                dicom_file = pydicom.dcmread(BytesIO(file.read()))\n",
    "                dicom_datasets.append(dicom_file)\n",
    "    return dicom_datasets\n",
    "\n",
    "\n",
    "# chargement de données médicales dicoms en mémoire depuis un répertoire de l'ordinateur : \n",
    "\n",
    "pathSlicesIRM = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/DATA_VERITE_TERRAIN/RM'\n",
    "\n",
    "# lecture des fichiers dicom avec pydicom\n",
    "\n",
    "dicom_datasets = load_dicom_files_from_directory(pathSlicesIRM)\n",
    "\n",
    "#################### API #############################################################################\n",
    "\n",
    "\n",
    "def dicom_to_nifti_in_memory(dicom_datasets: List[pydicom.Dataset]) -> nib.Nifti1Image:\n",
    "    image_slices = [ds.pixel_array for ds in dicom_datasets]\n",
    "    volume_3d = np.stack(image_slices, axis=-1)\n",
    "    affine = np.eye(4) # necessaire pour les algorithmes de traitement d'images médicales, ça permet de savoir comment les voxels sont disposés dans l'espace\n",
    "    nifti_image = nib.Nifti1Image(volume_3d, affine)\n",
    "    return nifti_image\n",
    "\n",
    "\n",
    "niftis =  dicom_to_nifti_in_memory(dicom_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2c3a447-3988-4e5c-9773-0733bed22d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "4\n",
      "----------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m pathModelFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/romain/Downloads/Modeles_Pre_Entraines/checkpoint_epoch1599_val_loss0255.cpkt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Charger les étiquettes pour les images DICOM\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#image, label, imageT = getLabelOfIRM_from_path(pathSlicesIRM2, pathModelFile)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m image, label, imageT \u001b[38;5;241m=\u001b[39m \u001b[43mgetLabelOfIRM_from_nifti\u001b[49m\u001b[43m(\u001b[49m\u001b[43mniftis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpathModelFile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Afficher les résultats\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, image\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[6], line 150\u001b[0m, in \u001b[0;36mgetLabelOfIRM_from_nifti\u001b[0;34m(nifti_image, pathModelFile)\u001b[0m\n\u001b[1;32m    148\u001b[0m model \u001b[38;5;241m=\u001b[39m loadModel(pathModelFile)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m#dico_image = {\"image\": transformed_image, \"label\": torch.zeros_like(transformed_image)}\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m dico_image \u001b[38;5;241m=\u001b[39m \u001b[43mapplyUNETR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m label, imageT \u001b[38;5;241m=\u001b[39m disapplyTransforms(transform, dico_image)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nifti_image\u001b[38;5;241m.\u001b[39mget_fdata() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m, label, imageT\n",
      "Cell \u001b[0;32mIn[6], line 115\u001b[0m, in \u001b[0;36mapplyUNETR\u001b[0;34m(dicoImage, model)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapplyUNETR\u001b[39m(dicoImage, model):\n\u001b[0;32m--> 115\u001b[0m     label \u001b[38;5;241m=\u001b[39m\u001b[43msliding_window_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdicoImage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mroi_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43msw_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(label, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m     size\u001b[38;5;241m=\u001b[39mlabel\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/monai/inferers/utils.py:130\u001b[0m, in \u001b[0;36msliding_window_inference\u001b[0;34m(inputs, roi_size, sw_batch_size, predictor, overlap, mode, sigma_scale, padding_mode, cval, sw_device, device, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m unravel_slice \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    126\u001b[0m     [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win), \u001b[38;5;28mint\u001b[39m(idx \u001b[38;5;241m/\u001b[39m num_win) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(slices[idx \u001b[38;5;241m%\u001b[39m num_win])\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m slice_range\n\u001b[1;32m    128\u001b[0m ]\n\u001b[1;32m    129\u001b[0m window_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([inputs[win_slice] \u001b[38;5;28;01mfor\u001b[39;00m win_slice \u001b[38;5;129;01min\u001b[39;00m unravel_slice])\u001b[38;5;241m.\u001b[39mto(sw_device)\n\u001b[0;32m--> 130\u001b[0m seg_prob \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# batched patch segmentation\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _initialized:  \u001b[38;5;66;03m# init. buffer at the first iteration\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     output_classes \u001b[38;5;241m=\u001b[39m seg_prob\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/P_R_O_J_E_C_T_S/IRM-Project/BrainMetaSegmentatorUI-Back/MetIA/unetr/model_module.py:197\u001b[0m, in \u001b[0;36mSegmentationTask.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/P_R_O_J_E_C_T_S/IRM-Project/BrainMetaSegmentatorUI-Back/MetIA/unetr/networks/unetr.py:387\u001b[0m, in \u001b[0;36mUNETR.forward\u001b[0;34m(self, x_in)\u001b[0m\n\u001b[1;32m    385\u001b[0m dec3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder5(dec4, enc4)\n\u001b[1;32m    386\u001b[0m dec2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder4(dec3, enc3)\n\u001b[0;32m--> 387\u001b[0m dec1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder2(dec1, enc1)\n\u001b[1;32m    389\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(out)\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/monai/networks/blocks/unetr_block.py:84\u001b[0m, in \u001b[0;36mUnetrUpBlock.forward\u001b[0;34m(self, inp, skip)\u001b[0m\n\u001b[1;32m     82\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransp_conv(inp)\n\u001b[1;32m     83\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((out, skip), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/monai/networks/blocks/dynunet_block.py:92\u001b[0m, in \u001b[0;36mUnetResBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     90\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(out)\n\u001b[1;32m     91\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(out)\n\u001b[0;32m---> 92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(out)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample:\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/conv.py:587\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/IRM/lib/python3.9/site-packages/torch/nn/modules/conv.py:582\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    572\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    573\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    581\u001b[0m     )\n\u001b[0;32m--> 582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Chemins vers les dossiers d'images DICOM et le modèle UNETR\n",
    "pathSlicesIRM = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/DATA_VERITE_TERRAIN/RM'\n",
    "pathSlicesIRM2 = '/Users/romain/Documents/P_R_O_J_E_C_T_S/IRM-Project/mbiaDataDownloads/nifti_s/201704321/image.nii.gz'\n",
    "pathModelFile = '/Users/romain/Downloads/Modeles_Pre_Entraines/checkpoint_epoch1599_val_loss0255.cpkt'\n",
    "\n",
    "# Charger les étiquettes pour les images DICOM\n",
    "#image, label, imageT = getLabelOfIRM_from_path(pathSlicesIRM2, pathModelFile)\n",
    "image, label, imageT = getLabelOfIRM_from_nifti(niftis, pathModelFile)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label shape:\", label.shape)\n",
    "print(\"Transformed image shape:\", imageT.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
